% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Samuelsson2021}
\BIBentryALTinterwordspacing
H.~Samuelsson, ``What percentage of trading is algorithmic?'' 2021. [Online].
  Available:
  \url{https://therobusttrader.com/what-percentage-of-trading-is-algorithmic/}
\BIBentrySTDinterwordspacing

\bibitem{Vonko2021}
\BIBentryALTinterwordspacing
D.~Vonko, ``Neural networks: Forecasting profits,'' 2021. [Online]. Available:
  \url{https://www.investopedia.com/articles/trading/06/neuralnetworks.asp}
\BIBentrySTDinterwordspacing

\bibitem{mesh-transformer-jax}
B.~Wang, ``{Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer
  Language Model with JAX},''
  \url{https://github.com/kingoflolz/mesh-transformer-jax}, May 2021.

\bibitem{Vaswani2017}
\BIBentryALTinterwordspacing
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' \emph{CoRR},
  vol. abs/1706.03762, 2017. [Online]. Available:
  \url{http://arxiv.org/abs/1706.03762}
\BIBentrySTDinterwordspacing

\bibitem{Gao2021}
\BIBentryALTinterwordspacing
L.~Gao, S.~Biderman, S.~Black, L.~Golding, T.~Hoppe, C.~Foster, J.~Phang,
  H.~He, A.~Thite, N.~Nabeshima, S.~Presser, and C.~Leahy, ``The pile: An 800gb
  dataset of diverse text for language modeling,'' \emph{CoRR}, vol.
  abs/2101.00027, 2021. [Online]. Available:
  \url{https://arxiv.org/abs/2101.00027}
\BIBentrySTDinterwordspacing

\bibitem{Chen2017}
\BIBentryALTinterwordspacing
G.~Chen, Y.~Chen, and T.~Fushimi, ``Application of deep learning to algorithmic
  trading,'' 2017. [Online]. Available:
  \url{http://cs229.stanford.edu/proj2017/final-reports/5241098.pdf}
\BIBentrySTDinterwordspacing

\bibitem{Mehta2021}
\BIBentryALTinterwordspacing
P.~Mehta, S.~Pandya, and K.~Kotecha, ``Harvesting social media sentiment
  analysis to enhance stock market prediction using deep learning,''
  \emph{{PeerJ} Computer Science}, vol.~7, p. e476, Apr. 2021. [Online].
  Available: \url{https://doi.org/10.7717/peerj-cs.476}
\BIBentrySTDinterwordspacing

\bibitem{Gu2020}
\BIBentryALTinterwordspacing
Y.~Gu, T.~Shibukawa, Y.~Kondo, S.~Nagao, and S.~Kamijo, ``Prediction of stock
  performance using deep neural networks,'' \emph{Applied Sciences}, vol.~10,
  no.~22, 2020. [Online]. Available:
  \url{https://www.mdpi.com/2076-3417/10/22/8142}
\BIBentrySTDinterwordspacing

\bibitem{Chen2015}
K.~Chen, Y.~Zhou, and F.~Dai, ``A lstm-based method for stock returns
  prediction: A case study of china stock market,'' in \emph{2015 IEEE
  International Conference on Big Data (Big Data)}, 2015, pp. 2823--2824.

\bibitem{Sezer2018}
\BIBentryALTinterwordspacing
O.~B. Sezer and A.~M. Ozbayoglu, ``Algorithmic financial trading with deep
  convolutional neural networks: Time series to image conversion approach,''
  \emph{Applied Soft Computing}, vol.~70, pp. 525--538, Sep. 2018. [Online].
  Available: \url{https://doi.org/10.1016/j.asoc.2018.04.024}
\BIBentrySTDinterwordspacing

\bibitem{Shi2020}
\BIBentryALTinterwordspacing
Y.~Shi, Y.~Zheng, K.~Guo, and X.~Ren, ``Stock movement prediction with
  sentiment analysis based on deep learning networks,'' \emph{Concurrency and
  Computation: Practice and Experience}, vol.~33, no.~6, Nov. 2020. [Online].
  Available: \url{https://doi.org/10.1002/cpe.6076}
\BIBentrySTDinterwordspacing

\bibitem{Wang2017}
\BIBentryALTinterwordspacing
Y.~Wang, D.~Wang, S.~Zhang, Y.~Feng, S.~Li, and Q.~Zhou, ``Deep q-trading,''
  2017. [Online]. Available:
  \url{http://cslt.riit.tsinghua.edu.cn/mediawiki/images/5/5f/Dtq.pdf}
\BIBentrySTDinterwordspacing

\bibitem{Nan2020}
A.~Nan, A.~Perumal, and O.~R. Zaiane, ``Sentiment and knowledge based
  algorithmic trading with deep reinforcement learning,'' 2020.

\bibitem{Li2019}
\BIBentryALTinterwordspacing
Y.~Li, W.~Zheng, and Z.~Zheng, ``Deep robust reinforcement learning for
  practical algorithmic trading,'' \emph{{IEEE} Access}, vol.~7, pp.
  108\,014--108\,022, 2019. [Online]. Available:
  \url{https://doi.org/10.1109/access.2019.2932789}
\BIBentrySTDinterwordspacing

\bibitem{Day2016}
\BIBentryALTinterwordspacing
M.-Y. Day and C.-C. Lee, ``Deep learning for financial sentiment analysis on
  finance news providers,'' in \emph{2016 {IEEE}/{ACM} International Conference
  on Advances in Social Networks Analysis and Mining ({ASONAM})}.\hskip 1em
  plus 0.5em minus 0.4em\relax {IEEE}, Aug. 2016. [Online]. Available:
  \url{https://doi.org/10.1109/asonam.2016.7752381}
\BIBentrySTDinterwordspacing

\bibitem{Schmitz2020}
\BIBentryALTinterwordspacing
J.~Schmitz, ``Stock predictions with state-of-the-art transformer and time
  embeddings,'' Sep 2020. [Online]. Available:
  \url{https://towardsdatascience.com/stock-predictions-with-state-of-the-art-transformer-and-time-embeddings-3a4485237de6}
\BIBentrySTDinterwordspacing

\bibitem{Brown2020}
\BIBentryALTinterwordspacing
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~Kaplan, P.~Dhariwal,
  A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal,
  A.~Herbert{-}Voss, G.~Krueger, T.~Henighan, R.~Child, A.~Ramesh, D.~M.
  Ziegler, J.~Wu, C.~Winter, C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray,
  B.~Chess, J.~Clark, C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and
  D.~Amodei, ``Language models are few-shot learners,'' \emph{CoRR}, vol.
  abs/2005.14165, 2020. [Online]. Available:
  \url{https://arxiv.org/abs/2005.14165}
\BIBentrySTDinterwordspacing

\bibitem{gpt-j}
B.~Wang and A.~Komatsuzaki, ``{GPT-J-6B: A 6 Billion Parameter Autoregressive
  Language Model},'' \url{https://github.com/kingoflolz/mesh-transformer-jax},
  May 2021.

\end{thebibliography}
