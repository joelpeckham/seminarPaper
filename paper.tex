\documentclass[conference]{IEEEtran}
\hyphenation{op-tical net-works semi-conduc-tor}
\usepackage{svg}
\usepackage{float}
\usepackage{tikz}
\usepackage{makecell}
\usepackage{url}
\def\UrlBreaks{\do\/\do-}
\usepackage{breakurl}
\usepackage[breaklinks]{hyperref}
\usepackage{lipsum}  


\begin{document}

\begin{titlepage}
	\centering
	\includegraphics[width=0.2\textwidth]{logoBlackV.eps}\par
	\vspace{1.5cm}
	{\scshape\LARGE Southern Adventist University \par}
	\vfill
	{\scshape\Large Senior Project\par}
	\vspace{1cm}
	{\huge\bfseries Algorithmically Trading like a Human with GPT-J\par}
	\vspace{1cm}
	{\large Joel \textsc{Peckham}\par}
	\textsc{Email:} joelskyler@gmail.com\par
	
	\vspace{0.5cm}
	supervised by\par
	Willard \textsc{Munger}, PhD.\par
	Robert \textsc{Ordóñez}, M.S.
	\vfill
	\begin{abstract}
		\lipsum[1]
	\end{abstract}
	
	\vfill
	
	% Bottom of the page
	{\large \today\par}
\end{titlepage}
\onecolumn
\tableofcontents
\listoffigures
\listoftables
\twocolumn

% \title{Algorithmically Trading like a Human with GPT-J}

% \author{\IEEEauthorblockN{Joel Peckham}
% \IEEEauthorblockA{School of Computing\\
% Southern Adventist University\\
% Collegedale, TN 37363\\
% Email: joelskyler@gmail.com}}

% \maketitle
% \begin{abstract}
%     \lipsum[1]
% \end{abstract}

% As a general rule, do not put math, special symbols or citations
% in the abstract
\section{Introduction}
\subsection{Background}
Algorithmic trading has become the dominant way of buying and selling securities. In the U.S. stock market, algorithms account for 70-80\% of trading volume \cite{Samuelsson2021}. The next generation of trading algorithms use neural networks to improve prediction accuracy. However, current opinion states neural networks can only increase efficiency by about 10\% and that neural networks are not capable of inventing winning trading ideas \cite{Vonko2021}. We theorize that neural networks are capable of much more. By scaling the number of network parameters into the billions, training the network on a massive dataset which captures the complexities of human behavior, and then making inferences from current  and by feeding the network with current news and opinons we believe that neural networks can model the world accurately enough to discover winning, novel trade ideas. Thankfully, the creators of GPT-J have already created such a neural network \cite{mesh-transformer-jax}. GPT-J is a transformer network \cite{Vaswani2017} that has been trained on an 825GiB language modelling data set called The Pile \cite{Gao2021}. 

\subsection{Intent}
We propose that with adequate fine-tuning and well engineered prompts, GPT-J can learn to trade like a human by reading the news, social media, and other sources such as SEC filings.

In this paper we will first implement a trading algorithm based on GPT-J, then we will evaluate the algorithm's prediction accuracy and compare it to the accuracy of similar algorithms. Finally, we will evaluate the real-world profitability of the algorithm using both backtesting and live market data. 

\subsection{Problem Statement}
In summary, as algorihmic traders seek to employ increasingly competitive and complex trading algorithms, we intend to evaluate the viability of using GPT languange models to drive trading decisions. To achieve this goal we must first implement a trading algorithm based on GPT-J, then evaluate the accuracy of the algorithm's predictions, and finally evaluate the real-world profitability of the algorithm.

\section{Background \& Related Works}
Many neural network structures and methods have been used to create trading algorithms. Some types include: 
\begin{itemize}
	\item Recurrent neural networks (RNNs) \& Long short-term memory (LSTMs) \cite{Chen2017}\cite{Mehta2021}.
	      \\\emph{These are the most widely used network architectures for trading \cite{Gu2020}. An LSTM trained on 900,000 sequences of length 30 days of Chinese stock market data yeilded an improvement of 12.9\% in prediction accuracy over a random guess \cite{Chen2015}.}
	\item Convolutional Neural Networks (CNNs) \cite{Gu2020}
	      \\\emph{CNNs can be used by converting time-series data into images \cite{Sezer2018}. Or they can be used to extract sentiment features from text \cite{Shi2020}.}
	\item Deep reinforment learning (DRN).
	      \begin{itemize}
	      	\item Deep Q-learning \cite{Wang2017} \cite{Nan2020}.
	      	\item Deep robust reinforcement learning \cite{Li2019}.
	      \end{itemize}
	\item Conventional deep learning \cite{Day2016}.
	\item Transformer networks \cite{Schmitz2020}.
\end{itemize}

Most relevent to our work are methods that incorperate sentiment analysis of news sources. Mehta et al. (2021) evaluated a sentiment analysis methods and found that LSTMs could properly classify news tweets as indicative of positive or negative price movement with an accuracy of 92\% correct \cite{Mehta2021}. Nan \& Zaiane (2020) found that adding sentiment analysis to a Deep-Q learning algorithm could improve the sharpe ratio of the agent by a factor greater than 2 in their test cases. \cite{Nan2020}.

By our estimation, the vast majortity of previous works involving sentiment analysis used a pre-processing step to extract sentiment from the news, and then embedded those features into a time-series dataset. News sources were often limited to headlines, tweets and small snippits because of the memory limitations of RNN sentiment classifiers. With the indruduction of large transformer networks \cite{Vaswani2017}, capable of processing large amounts of text like OpenAi's GPT-3 \cite{Brown2020} or Wang \& Komatsuzaki's GPT-J \cite{gpt-j}, we believe a new class of trading network can be created. Our method will encode the current world state in a large text-input wich combines sentiment, real-world facts, and stock price data into a single input. We believe that this new network can be trained to learn to trade like a human.

\section{Execution Plan}
\subsection{Requirements \& Goals}
\subsubsection{Functional requirements (user stories)}
\begin{itemize}
	\item As finance researchers, we want to quantify the ability of news releases, SEC filings, and social media posts to move stock prices.
	\item As AI researchers, we want to evaluate the viability of using GPT-J as a stock movement indicator so that we can understand the power of GPT-J to understand complex real-world interactions.
	\item As algorithmic traders, we want to evaluate the viability of using GPT-J as a stock movement indicator so that I can make more-informed trading decisions.
\end{itemize}
\subsubsection{Non-functional requirements}
Our overall flow of execution as outlined in figure \ref{fig:executionFlow} is as follows:
\begin{enumerate}
	\item[•] We will evaluate the correlations between the following items:
	      \begin{enumerate}
	      	\item The release of SEC filings for company X and large movements in the stock price of company X.
	      	\item The release of news stories mentioning company X and large movements in the stock price of company X.
	      	\item The posting of tweets or other social media posts mentioning company X and large movements in the stock price of company X.
	      \end{enumerate}
	\item[•] We will evaluate the best ways of formatting prompts for GPT-J to increase output accuracy and consistency across varying inputs. Some options might include:
	      \begin{enumerate}
	      	\item Providing a form for GPT-J to fill out appended to the end of the input data.
	      	\item Asking GPT-J a direct question appended to the end of the input data.
	      	\item Appending a universe current stock prices to the beginning of the input.
	      	\item Appending multiple news stories from the past days and weeks at the beginning of the input.
	      \end{enumerate}
	\item[•] We will deploy the best model from my previous evaluations and test it on live stock market data. I will compare the model's performance against market indices like the S\&P 500. 
\end{enumerate}

\begin{figure}[ht]
	\centering
	\scalebox{0.8}{
		\definecolor{lblue}{RGB}{220, 234, 240}
		\definecolor{dblue}{RGB}{0, 21, 79}
		\newcommand\bluebox[3]{\filldraw [draw=dblue,fill=lblue, line width=0.4mm] (#1-1.75,#2-0.75) rectangle (#1+1.75,#2+0.75) node[text=dblue, font=\footnotesize][midway] {\makecell[l]{#3}}}
		\newcommand\bluearrow[4]{\draw[dblue, -latex, line width=0.8mm] (#1,#2-0.75) -- (#3,#4+0.75);}
		\newcommand\bluearrownooffset[4]{\draw[dblue, -latex, line width=0.8mm] (#1,#2) -- (#3,#4);}
		\newcommand\blueline[4]{\draw[dblue, line width=0.8mm] (#1,#2) -- (#3,#4);}
		\begin{tikzpicture}
			\bluebox{0}{0}{\textbf{Gather test dataset.}\\(SEC filings, news, social\\media, stock price data)};
			\bluebox{0}{-2}{\textbf{Evaluate correlations}\\\textbf{between media release}\\\textbf{\& price movement.}};
			\bluebox{2}{-4}{\textbf{Change type of}\\\textbf{input media.}};
			\bluebox{0}{-6}{\textbf{Fine-tune training}\\\textbf{on GPT-J.}};
			\bluebox{2}{-8}{\textbf{Change format of}\\\textbf{input prompt.}};
			\bluebox{0}{-10}{\textbf{Evaluate prediction}\\\textbf{accuracy.}};
			\bluebox{0}{-12}{\textbf{Test and evaluate}\\\textbf{on live data.}};
			\bluearrow{0}{0}{0}{-2};
			\bluearrow{-1}{-2}{-1}{-6};
			\blueline{0.25}{-4}{-1}{-4};
			\bluearrow{-1}{-6}{-1}{-10};
			\blueline{0.25}{-8}{-1}{-8};
			\bluearrow{0}{-10}{0}{-12};
			\blueline{1.75}{-10}{4.21}{-10};
			\bluearrownooffset{2.75}{-10}{2.75}{-8.75};
			\blueline{4.25}{-4.04}{4.25}{-10.04};
			\bluearrownooffset{4.29}{-4}{3.75}{-4};
			\blueline{2.75}{-7.25}{2.75}{-5.96};
			\bluearrownooffset{2.75}{-6}{1.75}{-6};
		\end{tikzpicture}
	}
	\caption{Execution Flow}
	\label{fig:executionFlow}
\end{figure}
\subsection{Dataset Gathering}
\subsubsection{Stock Price Data}
We plan to use the publically availabe Yahoo Finance API \cite{yahoofinanceapi} to gather general technical information about a given ticker symbol. 
For historical price data, we will use the Alpaca Data API v2 \cite{alpacadataapi}. This API gives access to 5 years of historical data for training and live price data for live model inference testing. 
\subsubsection{SEC Filings}
The SEC provides public access to their EDGAR database of public company filings \cite{Sec.gov_2021}. The EDGAR API can be used to download the most recent SEC filings for a given company for live trading. Or for training, bulk datasets are available for download. The release dates of each filing can then be labeled with the stock prices of the company before and after the filing.
\subsubsection{News}
We will scrape financial news websites for a large set of historical articles. We intend to create a backlog of articles from the sources listed in Table \ref{table:newsSources}.
\begin{table}[ht]
    \caption{News Sources}
    \centering
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Source} & \textbf{URL} \\
        \hline
        Bloomberg & \href{https://www.bloomberg.com/}{www.bloomberg.com} \\
        \hline
        CNBC Finance & \href{https://www.cnbc.com/finance/}{www.cnbc.com/finance} \\
        \hline
        Reuters & \href{https://www.reuters.com/}{www.reuters.com} \\
        \hline
        Forbes & \href{https://www.forbes.com/}{www.forbes.com} \\
        \hline
        CNN Business & \href{https://www.cnn.com/business}{www.cnn.com/business} \\
        \hline
        Yahoo Finance & \href{https://finance.yahoo.com/news}{www.finance.yahoo.com/news} \\
        \hline
        Wall Street Journal & \href{https://www.wsj.com/}{www.wsj.com/} \\
        \hline
    \end{tabular}
    \label{table:newsSources}
\end{table}

\subsubsection{Social Media}
We will focus on Twitter for our social media data. The twitter API \cite{twitterapi} will allow us to gather timely opinions on a given ticker symbol. After filtering for a specific time period, tweets can be added to our training dataset.

\subsection{Testing \& Evaulation Methods}
\subsubsection{Media Release Correlations}
To measure the correlation between the release of a media item such as an SEC filing or news story, we will use the standard event study method as detailed in \cite{Neuhierl2010}. This method uses abormal returns in a given period to calculate the effect of a certian event on a stock's price. Abnormal return for a given day is defined as 
\begin{equation}
	AR_{i,t}=R_{i,t}-(\alpha_i+\beta_i R_{m,t})
\end{equation}
for firm $i$ at time $t$ where $\alpha_i$ and $\beta_i$ represent the relationship between a given stock and it's refrence index. And where $R_{m,t}$ is the return of the actual reference market.

We will then take large sample of media release events of the same type and calculate the average abnormal return as follows:
\begin{equation}
	AAR= \frac{1}{N} \sum\limits_{i=1}^{N}AR_{i,t}
\end{equation}

Finally, we meausre the total impact of the event over a given period of time by using cumulate abnormal return:
\begin{equation}
	CAR(t_1,t_2)=\sum\limits_{t=t_1}^{t_2} AR_{i,t} 
\end{equation}
where $t_1$ and $t_2$ are the start and end dates of the event window.
\subsubsection{GPT-J Model prediction accuracy}
To evaluate the accuracy of our model given different input data, we will use two metrics. First is a simple ratio of well-formed, parseable outputs to malformed outputs. This first metric we refer to as format-correctness. The second metric is a simple ratio of the actual stock price to the predicted stock price. This second metric we refer to as price-accuracy.
\section{Implementation}
\section{Conclusion}
The conclusion goes here.

\section*{Acknowledgment}
The authors would like to thank... 


\bibliographystyle{IEEEtran}
\bibliography{./paper.bib}

\end{document}